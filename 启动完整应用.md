# 🚀 启动完整应用指南

## ✅ 前置条件检查

- [x] Parallax LLM服务运行在端口3001
- [x] LLM分类测试通过（5/5成功）
- [x] 配置文件已更新（backend/.env）
- [x] 代码已适配Parallax API格式

## 📋 启动步骤

### 1. 启动后端服务

```bash
start_backend.bat
```

**预期输出**:
```
INFO:     Started server process
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://127.0.0.1:8000
```

**验证**:
- 访问 http://127.0.0.1:8000/docs 查看API文档
- 应该看到 `/api/v1/classify` 端点

### 2. 启动前端服务

```bash
start_frontend.bat
```

**预期输出**:
```
VITE ready in XXX ms
Local:   http://localhost:5173/
```

**验证**:
- 访问 http://localhost:5173
- 应该看到登录/注册页面

### 3. 测试完整流程

#### 3.1 用户注册/登录
1. 访问 http://localhost:5173
2. 注册新用户或登录
3. 验证JWT token生成

#### 3.2 文件上传
1. 上传图片文件（JPG/PNG/BMP）
2. 验证文件格式和大小检查
3. 确认文件成功上传

#### 3.3 OCR识别
1. 对上传的图片进行OCR识别
2. 查看识别结果
3. 可以手动编辑识别文本

#### 3.4 LLM分类（重点测试）
1. 输入或识别文本后，点击分类
2. 观察LLM分类结果
3. 验证分类类型（schedule/memo）
4. 检查置信度和提取的数据

**测试用例**:
- "明天下午2点开会" → 应分类为 schedule
- "今天学习了Python" → 应分类为 memo
- "2024年1月15日项目评审" → 应分类为 schedule

#### 3.5 数据存储
1. 确认分类后的数据正确存储
2. 查看日程列表
3. 查看备忘录列表
4. 验证数据持久化

## 🔍 监控和调试

### 查看后端日志
```bash
# 日志文件位置
backend/logs/app-YYYY-MM-DD.log
```

**关键日志**:
- `"分类服务初始化成功 (LLM模式: True)"` - LLM已启用
- `"用户 XXX 对文本进行分类"` - 分类请求
- `"LLM分类失败，使用规则方法"` - 降级事件

### 查看LLM服务日志
```bash
# 如果使用Docker
docker logs parallax-server

# 或查看Parallax控制台输出
```

### 测试API端点

**测试分类API**:
```bash
# 需要先获取token
curl -X POST http://localhost:8000/api/v1/classify \
  -H "Authorization: Bearer YOUR_TOKEN" \
  -H "Content-Type: application/json" \
  -d '{"text":"明天下午2点开会"}'
```

## 🐛 常见问题

### 问题1: 后端启动失败

**症状**: 端口8000被占用

**解决**:
```bash
# 查找占用端口的进程
netstat -ano | findstr :8000

# 或修改端口
# 编辑 backend/.env
PORT=8001
```

### 问题2: LLM分类超时

**症状**: 请求超时或响应很慢

**解决**:
1. 检查Parallax服务状态
2. 增加超时时间（在ClassificationService中）
3. 系统会自动降级到规则方法

### 问题3: 分类结果不准确

**症状**: LLM分类错误

**解决**:
1. 检查prompt设计
2. 调整temperature参数
3. 查看LLM原始响应
4. 系统会显示置信度，低置信度时提示手动选择

### 问题4: 前端无法连接后端

**症状**: API请求失败

**解决**:
1. 确认后端运行在8000端口
2. 检查CORS配置
3. 验证JWT token有效性

## 📊 性能指标

### 预期性能
- **OCR识别**: 2-5秒/图片
- **LLM分类**: 2-4秒/文本
- **规则分类**: <100ms/文本
- **API响应**: <500ms（不含LLM）

### 资源使用
- **后端内存**: ~500MB
- **前端内存**: ~200MB
- **LLM服务**: ~8GB（GPU）或~4GB（CPU）

## ✅ 验收标准

完整流程测试通过的标准：

- [ ] 用户可以注册和登录
- [ ] 可以上传图片文件
- [ ] OCR可以识别图片中的文字
- [ ] LLM可以正确分类文本
- [ ] 日程和备忘录分别存储
- [ ] 可以查看和筛选数据
- [ ] 数据在刷新后仍然存在

## 🎯 下一步

完成测试后：

1. **性能优化**
   - 添加响应缓存
   - 批量处理
   - 数据库索引优化

2. **功能增强**
   - 搜索功能
   - 数据导出
   - 统计分析

3. **部署准备**
   - 生产环境配置
   - 数据库迁移
   - 监控和告警

## 📚 相关文档

- **LLM_TEST_SUCCESS.md** - LLM测试成功报告
- **WINDOWS_LLM_SETUP.md** - Windows部署指南
- **LLM_INTEGRATION_README.md** - 架构说明
- **TESTING_GUIDE.md** - 测试指南

---

## 🎉 准备就绪！

现在运行：
```bash
# 1. 启动后端
start_backend.bat

# 2. 启动前端（新窗口）
start_frontend.bat

# 3. 访问应用
# http://localhost:5173
```

**祝测试顺利！** 🚀
